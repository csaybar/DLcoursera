{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularization+-+v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "L2bgb8XiUh_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "Welcome to the second assignment of this week. Deep Learning models have so much flexibility and capacity that **overfitting can be a serious problem**, if the training dataset is not big enough. Sure it does well on the training set, but the learned network **doesn't generalize to new examples** that it has never seen!\n",
        "\n",
        "**You will learn to:** Use regularization in your deep learning models.\n",
        "\n",
        "Let's first import the packages you are going to use."
      ]
    },
    {
      "metadata": {
        "id": "M9r2W2V8Ujn8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title reg_utils\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import scipy.io\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of x\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size.\n",
        "\n",
        "    Return:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"\n",
        "    Compute the relu of x\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size.\n",
        "\n",
        "    Return:\n",
        "    s -- relu(x)\n",
        "    \"\"\"\n",
        "    s = np.maximum(0,x)\n",
        "    \n",
        "    return s\n",
        "\n",
        "def load_planar_dataset(seed):\n",
        "    \n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    m = 400 # number of examples\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 4 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        ix = range(N*j,N*(j+1))\n",
        "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
        "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
        "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "        Y[ix] = j\n",
        "        \n",
        "    X = X.T\n",
        "    Y = Y.T\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def initialize_parameters(layer_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    b1 -- bias vector of shape (layer_dims[l], 1)\n",
        "                    Wl -- weight matrix of shape (layer_dims[l-1], layer_dims[l])\n",
        "                    bl -- bias vector of shape (1, layer_dims[l])\n",
        "                    \n",
        "    Tips:\n",
        "    - For example: the layer_dims for the \"Planar Data classification model\" would have been [2,2,1]. \n",
        "    This means W1's shape was (2,2), b1 was (1,2), W2 was (2,1) and b2 was (1,1). Now you have to generalize it!\n",
        "    - In the for loop, use parameters['W' + str(l)] to access Wl, where l is the iterative integer.\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims) # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "        \n",
        "    return parameters\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation (and computes the loss) presented in Figure 2.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\":\n",
        "                    W1 -- weight matrix of shape ()\n",
        "                    b1 -- bias vector of shape ()\n",
        "                    W2 -- weight matrix of shape ()\n",
        "                    b2 -- bias vector of shape ()\n",
        "                    W3 -- weight matrix of shape ()\n",
        "                    b3 -- bias vector of shape ()\n",
        "    \n",
        "    Returns:\n",
        "    loss -- the loss function (vanilla logistic loss)\n",
        "    \"\"\"\n",
        "        \n",
        "    # retrieve parameters\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    b3 = parameters[\"b3\"]\n",
        "    \n",
        "    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = relu(Z2)\n",
        "    Z3 = np.dot(W3, A2) + b3\n",
        "    A3 = sigmoid(Z3)\n",
        "    \n",
        "    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3)\n",
        "    \n",
        "    return A3, cache\n",
        "\n",
        "def backward_propagation(X, Y, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation presented in figure 2.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat)\n",
        "    cache -- cache output from forward_propagation()\n",
        "    \n",
        "    Returns:\n",
        "    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache\n",
        "    \n",
        "    dZ3 = A3 - Y\n",
        "    dW3 = 1./m * np.dot(dZ3, A2.T)\n",
        "    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)\n",
        "    \n",
        "    dA2 = np.dot(W3.T, dZ3)\n",
        "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
        "    dW2 = 1./m * np.dot(dZ2, A1.T)\n",
        "    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)\n",
        "    \n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n",
        "    dW1 = 1./m * np.dot(dZ1, X.T)\n",
        "    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)\n",
        "    \n",
        "    gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\n",
        "                 \"dA2\": dA2, \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2,\n",
        "                 \"dA1\": dA1, \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
        "    \n",
        "    return gradients\n",
        "\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters:\n",
        "                    parameters['W' + str(i)] = Wi\n",
        "                    parameters['b' + str(i)] = bi\n",
        "    grads -- python dictionary containing your gradients for each parameters:\n",
        "                    grads['dW' + str(i)] = dWi\n",
        "                    grads['db' + str(i)] = dbi\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    \"\"\"\n",
        "    \n",
        "    n = len(parameters) // 2 # number of layers in the neural networks\n",
        "\n",
        "    # Update rule for each parameter\n",
        "    for k in range(n):\n",
        "        parameters[\"W\" + str(k+1)] = parameters[\"W\" + str(k+1)] - learning_rate * grads[\"dW\" + str(k+1)]\n",
        "        parameters[\"b\" + str(k+1)] = parameters[\"b\" + str(k+1)] - learning_rate * grads[\"db\" + str(k+1)]\n",
        "        \n",
        "    return parameters\n",
        "\n",
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  n-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    p = np.zeros((1,m), dtype = np.int)\n",
        "    \n",
        "    # Forward propagation\n",
        "    a3, caches = forward_propagation(X, parameters)\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, a3.shape[1]):\n",
        "        if a3[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "\n",
        "    # print results\n",
        "\n",
        "    #print (\"predictions: \" + str(p[0,:]))\n",
        "    #print (\"true labels: \" + str(y[0,:]))\n",
        "    print(\"Accuracy: \"  + str(np.mean((p[0,:] == y[0,:]))))\n",
        "    \n",
        "    return p\n",
        "\n",
        "def compute_cost(a3, Y):\n",
        "    \"\"\"\n",
        "    Implement the cost function\n",
        "    \n",
        "    Arguments:\n",
        "    a3 -- post-activation, output of forward propagation\n",
        "    Y -- \"true\" labels vector, same shape as a3\n",
        "    \n",
        "    Returns:\n",
        "    cost - value of the cost function\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]\n",
        "    \n",
        "    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n",
        "    cost = 1./m * np.nansum(logprobs)\n",
        "    \n",
        "    return cost\n",
        "\n",
        "import urllib\n",
        "def download():          \n",
        "  url = 'https://github.com/csaybar/DLcoursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/week5/Regularization/dataset/'\n",
        "  files = ['train_X', 'train_Y', 'test_X', 'test_Y']  \n",
        "  for x in files:\n",
        "    urllib.request.urlretrieve(url + x + '.npy',x + '.npy')\n",
        "  train = url + 'train_catvnoncat.h5'\n",
        "  urllib.request.urlretrieve(train,'train_catvnoncat.h5')\n",
        "  \n",
        "  test = url + 'test_catvnoncat.h5'\n",
        "  urllib.request.urlretrieve(test,'test_catvnoncat.h5')\n",
        "\n",
        "download()\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    train_set_x_orig = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
        "    test_set_x_orig = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
        "    \n",
        "    train_set_x = train_set_x_orig/255\n",
        "    test_set_x = test_set_x_orig/255\n",
        "\n",
        "    return train_set_x, train_set_y, test_set_x, test_set_y, classes\n",
        "\n",
        "\n",
        "def predict_dec(parameters, X):\n",
        "    \"\"\"\n",
        "    Used for plotting decision boundary.\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    X -- input data of size (m, K)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Predict using forward propagation and a classification threshold of 0.5\n",
        "    a3, cache = forward_propagation(X, parameters)\n",
        "    predictions = (a3>0.5)\n",
        "    return predictions\n",
        "\n",
        "def load_planar_dataset(randomness, seed):\n",
        "    \n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    m = 50\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 2 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        \n",
        "        ix = range(N*j,N*(j+1))\n",
        "        if j == 0:\n",
        "            t = np.linspace(j, 4*3.1415*(j+1),N) #+ np.random.randn(N)*randomness # theta\n",
        "            r = 0.3*np.square(t) + np.random.randn(N)*randomness # radius\n",
        "        if j == 1:\n",
        "            t = np.linspace(j, 2*3.1415*(j+1),N) #+ np.random.randn(N)*randomness # theta\n",
        "            r = 0.2*np.square(t) + np.random.randn(N)*randomness # radius\n",
        "            \n",
        "        X[ix] = np.c_[r*np.cos(t), r*np.sin(t)]\n",
        "        Y[ix] = j\n",
        "        \n",
        "    X = X.T\n",
        "    Y = Y.T\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
        "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    # Predict the function value for the whole grid\n",
        "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # Plot the contour and training examples\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
        "    plt.ylabel('x2')\n",
        "    plt.xlabel('x1')\n",
        "    plt.scatter(X[0, :], X[1, :], c=y[0], cmap=plt.cm.Spectral)\n",
        "    plt.show()\n",
        "    \n",
        "def load_2D_dataset():   \n",
        "    train_X = np.load('train_X.npy')\n",
        "    train_Y = np.load('train_Y.npy')\n",
        "    test_X = np.load('test_X.npy')\n",
        "    test_Y = np.load('test_X.npy')\n",
        "\n",
        "    plt.scatter(train_X[0, :], train_X[1, :], c=train_Y[0], s=40, cmap=plt.cm.Spectral);\n",
        "    \n",
        "    return train_X, train_Y, test_X, test_Y  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8Yh-LlpUjex",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title testCases\n",
        "import numpy as np\n",
        "\n",
        "def compute_cost_with_regularization_test_case():\n",
        "    np.random.seed(1)\n",
        "    Y_assess = np.array([[1, 1, 0, 1, 0]])\n",
        "    W1 = np.random.randn(2, 3)\n",
        "    b1 = np.random.randn(2, 1)\n",
        "    W2 = np.random.randn(3, 2)\n",
        "    b2 = np.random.randn(3, 1)\n",
        "    W3 = np.random.randn(1, 3)\n",
        "    b3 = np.random.randn(1, 1)\n",
        "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\": W3, \"b3\": b3}\n",
        "    a3 = np.array([[ 0.40682402,  0.01629284,  0.16722898,  0.10118111,  0.40682402]])\n",
        "    return a3, Y_assess, parameters\n",
        "\n",
        "def backward_propagation_with_regularization_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(3, 5)\n",
        "    Y_assess = np.array([[1, 1, 0, 1, 0]])\n",
        "    cache = (np.array([[-1.52855314,  3.32524635,  2.13994541,  2.60700654, -0.75942115],\n",
        "         [-1.98043538,  4.1600994 ,  0.79051021,  1.46493512, -0.45506242]]),\n",
        "  np.array([[ 0.        ,  3.32524635,  2.13994541,  2.60700654,  0.        ],\n",
        "         [ 0.        ,  4.1600994 ,  0.79051021,  1.46493512,  0.        ]]),\n",
        "  np.array([[-1.09989127, -0.17242821, -0.87785842],\n",
        "         [ 0.04221375,  0.58281521, -1.10061918]]),\n",
        "  np.array([[ 1.14472371],\n",
        "         [ 0.90159072]]),\n",
        "  np.array([[ 0.53035547,  5.94892323,  2.31780174,  3.16005701,  0.53035547],\n",
        "         [-0.69166075, -3.47645987, -2.25194702, -2.65416996, -0.69166075],\n",
        "         [-0.39675353, -4.62285846, -2.61101729, -3.22874921, -0.39675353]]),\n",
        "  np.array([[ 0.53035547,  5.94892323,  2.31780174,  3.16005701,  0.53035547],\n",
        "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
        "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]),\n",
        "  np.array([[ 0.50249434,  0.90085595],\n",
        "         [-0.68372786, -0.12289023],\n",
        "         [-0.93576943, -0.26788808]]),\n",
        "  np.array([[ 0.53035547],\n",
        "         [-0.69166075],\n",
        "         [-0.39675353]]),\n",
        "  np.array([[-0.3771104 , -4.10060224, -1.60539468, -2.18416951, -0.3771104 ]]),\n",
        "  np.array([[ 0.40682402,  0.01629284,  0.16722898,  0.10118111,  0.40682402]]),\n",
        "  np.array([[-0.6871727 , -0.84520564, -0.67124613]]),\n",
        "  np.array([[-0.0126646]]))\n",
        "    return X_assess, Y_assess, cache\n",
        "\n",
        "def forward_propagation_with_dropout_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(3, 5)\n",
        "    W1 = np.random.randn(2, 3)\n",
        "    b1 = np.random.randn(2, 1)\n",
        "    W2 = np.random.randn(3, 2)\n",
        "    b2 = np.random.randn(3, 1)\n",
        "    W3 = np.random.randn(1, 3)\n",
        "    b3 = np.random.randn(1, 1)\n",
        "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\": W3, \"b3\": b3}\n",
        "    \n",
        "    return X_assess, parameters\n",
        "\n",
        "def backward_propagation_with_dropout_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(3, 5)\n",
        "    Y_assess = np.array([[1, 1, 0, 1, 0]])\n",
        "    cache = (np.array([[-1.52855314,  3.32524635,  2.13994541,  2.60700654, -0.75942115],\n",
        "           [-1.98043538,  4.1600994 ,  0.79051021,  1.46493512, -0.45506242]]), np.array([[ True, False,  True,  True,  True],\n",
        "           [ True,  True,  True,  True, False]], dtype=bool), np.array([[ 0.        ,  0.        ,  4.27989081,  5.21401307,  0.        ],\n",
        "           [ 0.        ,  8.32019881,  1.58102041,  2.92987024,  0.        ]]), np.array([[-1.09989127, -0.17242821, -0.87785842],\n",
        "           [ 0.04221375,  0.58281521, -1.10061918]]), np.array([[ 1.14472371],\n",
        "           [ 0.90159072]]), np.array([[ 0.53035547,  8.02565606,  4.10524802,  5.78975856,  0.53035547],\n",
        "           [-0.69166075, -1.71413186, -3.81223329, -4.61667916, -0.69166075],\n",
        "           [-0.39675353, -2.62563561, -4.82528105, -6.0607449 , -0.39675353]]), np.array([[ True, False,  True, False,  True],\n",
        "           [False,  True, False,  True,  True],\n",
        "           [False, False,  True, False, False]], dtype=bool), np.array([[ 1.06071093,  0.        ,  8.21049603,  0.        ,  1.06071093],\n",
        "           [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
        "           [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]), np.array([[ 0.50249434,  0.90085595],\n",
        "           [-0.68372786, -0.12289023],\n",
        "           [-0.93576943, -0.26788808]]), np.array([[ 0.53035547],\n",
        "           [-0.69166075],\n",
        "           [-0.39675353]]), np.array([[-0.7415562 , -0.0126646 , -5.65469333, -0.0126646 , -0.7415562 ]]), np.array([[ 0.32266394,  0.49683389,  0.00348883,  0.49683389,  0.32266394]]), np.array([[-0.6871727 , -0.84520564, -0.67124613]]), np.array([[-0.0126646]]))\n",
        "\n",
        "\n",
        "    return X_assess, Y_assess, cache\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nj1n6iOtUh_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import scipy.io\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Gt6XnxurUh_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**: You have just been hired as an AI expert by the French Football Corporation. They would like you to recommend positions where France's goal keeper should kick the ball so that the French team's players can then hit it with their head. \n",
        "\n",
        "<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/week5/Regularization/images/field_kiank.png?raw=1\" style=\"width:600px;height:350px;\">\n",
        "<caption><center> <u> **Figure 1** </u>: **Football field**<br> The goal keeper kicks the ball in the air, the players of each team are fighting to hit the ball with their head </center></caption>\n",
        "\n",
        "\n",
        "They give you the following 2D dataset from France's past 10 games."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "xczjK-v6Uh_g",
        "colab_type": "code",
        "outputId": "e3b5e4a4-4dc6-482d-a1da-66d9a0b67714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "train_X, train_Y, test_X, test_Y = load_2D_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAD4CAYAAABbl2n6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naJwYXiGEEBonhlcIIYTGieEVQgihcf4FCHwsq/9esBQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qKL2kTx8Uh_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each dot corresponds to a position on the football field where a football player has hit the ball with his/her head after the French goal keeper has shot the ball from the left side of the football field.\n",
        "- If the dot is blue, it means the French player managed to hit the ball with his/her head\n",
        "- If the dot is red, it means the other team's player hit the ball with their head\n",
        "\n",
        "**Your goal**: Use a deep learning model to find the positions on the field where the goalkeeper should kick the ball."
      ]
    },
    {
      "metadata": {
        "id": "nXCAiXFtUh_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Analysis of the dataset**: This dataset is a little noisy, but it looks like a diagonal line separating the upper left half (blue) from the lower right half (red) would work well. \n",
        "\n",
        "You will first try a non-regularized model. Then you'll learn how to regularize it and decide which model you will choose to solve the French Football Corporation's problem. "
      ]
    },
    {
      "metadata": {
        "id": "my_qKgXVUh_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 - Non-regularized model\n",
        "\n",
        "You will use the following neural network (already implemented for you below). This model can be used:\n",
        "- in *regularization mode* -- by setting the `lambd` input to a non-zero value. We use \"`lambd`\" instead of \"`lambda`\" because \"`lambda`\" is a reserved keyword in Python. \n",
        "- in *dropout mode* -- by setting the `keep_prob` to a value less than one\n",
        "\n",
        "You will first try the model without any regularization. Then, you will implement:\n",
        "- *L2 regularization* -- functions: \"`compute_cost_with_regularization()`\" and \"`backward_propagation_with_regularization()`\"\n",
        "- *Dropout* -- functions: \"`forward_propagation_with_dropout()`\" and \"`backward_propagation_with_dropout()`\"\n",
        "\n",
        "In each part, you will run this model with the correct inputs so that it calls the functions you've implemented. Take a look at the code below to familiarize yourself with the model."
      ]
    },
    {
      "metadata": {
        "id": "Xcc_8oAwUh_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True, lambd = 0, keep_prob = 1):\n",
        "    \"\"\"\n",
        "    Implements a three-layer neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    print_cost -- If True, print the cost every 10000 iterations\n",
        "    lambd -- regularization hyperparameter, scalar\n",
        "    keep_prob - probability of keeping a neuron active during drop-out, scalar.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learned by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "        \n",
        "    grads = {}\n",
        "    costs = []                            # to keep track of the cost\n",
        "    m = X.shape[1]                        # number of examples\n",
        "    layers_dims = [X.shape[0], 20, 3, 1]\n",
        "    \n",
        "    # Initialize parameters dictionary.\n",
        "    parameters = initialize_parameters(layers_dims)\n",
        "\n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
        "        if keep_prob == 1:\n",
        "            a3, cache = forward_propagation(X, parameters)\n",
        "        elif keep_prob < 1:\n",
        "            a3, cache = forward_propagation_with_dropout(X, parameters, keep_prob)\n",
        "        \n",
        "        # Cost function\n",
        "        if lambd == 0:\n",
        "            cost = compute_cost(a3, Y)\n",
        "        else:\n",
        "            cost = compute_cost_with_regularization(a3, Y, parameters, lambd)\n",
        "            \n",
        "        # Backward propagation.\n",
        "        assert(lambd==0 or keep_prob==1)    # it is possible to use both L2 regularization and dropout, \n",
        "                                            # but this assignment will only explore one at a time\n",
        "        if lambd == 0 and keep_prob == 1:\n",
        "            grads = backward_propagation(X, Y, cache)\n",
        "        elif lambd != 0:\n",
        "            grads = backward_propagation_with_regularization(X, Y, cache, lambd)\n",
        "        elif keep_prob < 1:\n",
        "            grads = backward_propagation_with_dropout(X, Y, cache, keep_prob)\n",
        "        \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        \n",
        "        # Print the loss every 10000 iterations\n",
        "        if print_cost and i % 10000 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            costs.append(cost)\n",
        "    \n",
        "    # plot the cost\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (x1,000)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GdINoZQUh_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's train the model without any regularization, and observe the accuracy on the train/test sets."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "8hGIeUspUh_q",
        "colab_type": "code",
        "outputId": "674b0939-45f9-4816-a919-ddca37de27bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(train_X, train_Y)\n",
        "print (\"On the training set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.6557412523481002\n",
            "Cost after iteration 10000: 0.1632998752572417\n",
            "Cost after iteration 20000: 0.13851642423284755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEVCAYAAACSSPCDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQiSQEnIiKRpIATEZFIUsCJiEgk/X/rP+cZvZzKGwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "On the training set:\n",
            "Accuracy: 0.9478672985781991\n",
            "On the test set:\n",
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8TPYbXiUh_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The train accuracy is 94.8% while the test accuracy is 91.5%. This is the **baseline model** (you will observe the impact of regularization on this model). Run the following code to plot the decision boundary of your model."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "1XRaag3lUh_w",
        "colab_type": "code",
        "outputId": "5ad3bb0c-259e-4667-d185-c7d72d19e135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1565
        }
      },
      "cell_type": "code",
      "source": [
        "plt.title(\"Model without regularization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-0.75,0.40])\n",
        "axes.set_ylim([-0.75,0.65])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4231\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4232\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4233\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA sequence should have length 3 or 4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA sequence should have length 3 or 4",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-1c83d5b7143d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.65\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-95-9b2d0d0a149b>\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpectral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2862\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2863\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4243\u001b[0m                         \u001b[0;34m\"acceptable for use with 'x' with size {xs}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                         \u001b[0;34m\"'y' with size {ys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4245\u001b[0;31m                         \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4246\u001b[0m                     )\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;31m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'c' argument has 1 elements, which is not acceptable for use with 'x' with size 211, 'y' with size 211."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAAEVCAYAAAB+PZWVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YZpqlbJOUh_z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The non-regularized model is obviously overfitting the training set. It is fitting the noisy points! Lets now look at two techniques to reduce overfitting."
      ]
    },
    {
      "metadata": {
        "id": "sUdJp1nAUh_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 - L2 Regularization\n",
        "\n",
        "The standard way to avoid overfitting is called **L2 regularization**. It consists of appropriately modifying your cost function, from:\n",
        "$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small  y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} \\tag{1}$$\n",
        "To:\n",
        "$$J_{regularized} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} }_\\text{cross-entropy cost} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{L2 regularization cost} \\tag{2}$$\n",
        "\n",
        "Let's modify your cost and observe the consequences.\n",
        "\n",
        "**Exercise**: Implement `compute_cost_with_regularization()` which computes the cost given by formula (2). To calculate $\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2}$  , use :\n",
        "```python\n",
        "np.sum(np.square(Wl))\n",
        "```\n",
        "Note that you have to do this for $W^{[1]}$, $W^{[2]}$ and $W^{[3]}$, then sum the three terms and multiply by $ \\frac{1}{m} \\frac{\\lambda}{2} $."
      ]
    },
    {
      "metadata": {
        "id": "r4tT6fTWUh_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: compute_cost_with_regularization\n",
        "\n",
        "def compute_cost_with_regularization(A3, Y, parameters, lambd):\n",
        "    \"\"\"\n",
        "    Implement the cost function with L2 regularization. See formula (2) above.\n",
        "    \n",
        "    Arguments:\n",
        "    A3 -- post-activation, output of forward propagation, of shape (output size, number of examples)\n",
        "    Y -- \"true\" labels vector, of shape (output size, number of examples)\n",
        "    parameters -- python dictionary containing parameters of the model\n",
        "    \n",
        "    Returns:\n",
        "    cost - value of the regularized loss function (formula (2))\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]\n",
        "    W1 = parameters[\"W1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    \n",
        "    cross_entropy_cost = compute_cost(A3, Y) # This gives you the cross-entropy part of the cost\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 1 line)\n",
        "    L2_regularization_cost = lambd*(np.sum(np.square(W1))+np.sum(np.square(W2))+np.sum(np.square(W3)))/(2*m)\n",
        "    ### END CODER HERE ###\n",
        "    \n",
        "    cost = cross_entropy_cost + L2_regularization_cost\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0sZW6ODUh_3",
        "colab_type": "code",
        "outputId": "d84335c1-5cac-43ee-acfd-1069f0a01268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "A3, Y_assess, parameters = compute_cost_with_regularization_test_case()\n",
        "\n",
        "print(\"cost = \" + str(compute_cost_with_regularization(A3, Y_assess, parameters, lambd = 0.1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost = 1.7864859451590758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ppBzm7IUh_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**: \n",
        "\n",
        "<table> \n",
        "    <tr>\n",
        "    <td>\n",
        "    **cost**\n",
        "    </td>\n",
        "        <td>\n",
        "    1.78648594516\n",
        "    </td>\n",
        "    \n",
        "    </tr>\n",
        "\n",
        "</table> "
      ]
    },
    {
      "metadata": {
        "id": "uRX3tPRBUh_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Of course, because you changed the cost, you have to change backward propagation as well! All the gradients have to be computed with respect to this new cost. \n",
        "\n",
        "**Exercise**: Implement the changes needed in backward propagation to take into account regularization. The changes only concern dW1, dW2 and dW3. For each, you have to add the regularization term's gradient ($\\frac{d}{dW} ( \\frac{1}{2}\\frac{\\lambda}{m}  W^2) = \\frac{\\lambda}{m} W$)."
      ]
    },
    {
      "metadata": {
        "id": "XEkjo2MZUh_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: backward_propagation_with_regularization\n",
        "\n",
        "def backward_propagation_with_regularization(X, Y, cache, lambd):\n",
        "    \"\"\"\n",
        "    Implements the backward propagation of our baseline model to which we added an L2 regularization.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset, of shape (input size, number of examples)\n",
        "    Y -- \"true\" labels vector, of shape (output size, number of examples)\n",
        "    cache -- cache output from forward_propagation()\n",
        "    lambd -- regularization hyperparameter, scalar\n",
        "    \n",
        "    Returns:\n",
        "    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache\n",
        "    \n",
        "    dZ3 = A3 - Y\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 1 line)\n",
        "    dW3 = 1./m * np.dot(dZ3, A2.T) + (lambd * W3) / m\n",
        "    ### END CODE HERE ###\n",
        "    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)\n",
        "    \n",
        "    dA2 = np.dot(W3.T, dZ3)\n",
        "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
        "    ### START CODE HERE ### (approx. 1 line)\n",
        "    dW2 = 1./m * np.dot(dZ2, A1.T) + (lambd * W2) / m\n",
        "    ### END CODE HERE ###\n",
        "    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)\n",
        "    \n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n",
        "    ### START CODE HERE ### (approx. 1 line)\n",
        "    dW1 = 1./m * np.dot(dZ1, X.T) + (lambd * W1) / m\n",
        "    ### END CODE HERE ###\n",
        "    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)\n",
        "    \n",
        "    gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\"dA2\": dA2,\n",
        "                 \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2, \"dA1\": dA1, \n",
        "                 \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
        "    \n",
        "    return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0FuOs97oUh_-",
        "colab_type": "code",
        "outputId": "3bcc55a1-4a5c-4ed4-a78b-fda6b33c058d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_assess, Y_assess, cache = backward_propagation_with_regularization_test_case()\n",
        "\n",
        "grads = backward_propagation_with_regularization(X_assess, Y_assess, cache, lambd = 0.7)\n",
        "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
        "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
        "print (\"dW3 = \"+ str(grads[\"dW3\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dW1 = [[-0.25604646  0.12298827 -0.28297129]\n",
            " [-0.17706303  0.34536094 -0.4410571 ]]\n",
            "dW2 = [[ 0.79276486  0.85133918]\n",
            " [-0.0957219  -0.01720463]\n",
            " [-0.13100772 -0.03750433]]\n",
            "dW3 = [[-1.77691347 -0.11832879 -0.09397446]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "esY4m9wHUiAB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table> \n",
        "    <tr>\n",
        "    <td>\n",
        "    **dW1**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[-0.25604646  0.12298827 -0.28297129]\n",
        " [-0.17706303  0.34536094 -0.4410571 ]]\n",
        "    </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "    <td>\n",
        "    **dW2**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[ 0.79276486  0.85133918]\n",
        " [-0.0957219  -0.01720463]\n",
        " [-0.13100772 -0.03750433]]\n",
        "    </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "    <td>\n",
        "    **dW3**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[-1.77691347 -0.11832879 -0.09397446]]\n",
        "    </td>\n",
        "    </tr>\n",
        "</table> "
      ]
    },
    {
      "metadata": {
        "id": "u9Vy48-yUiAC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now run the model with L2 regularization $(\\lambda = 0.7)$. The `model()` function will call: \n",
        "- `compute_cost_with_regularization` instead of `compute_cost`\n",
        "- `backward_propagation_with_regularization` instead of `backward_propagation`"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "cII11sFBUiAD",
        "colab_type": "code",
        "outputId": "d0fe9fea-257e-453b-86e5-cee700ff2652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(train_X, train_Y, lambd = 0.7)\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.6974484493131264\n",
            "Cost after iteration 10000: 0.26849188732822393\n",
            "Cost after iteration 20000: 0.2680916337127301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEVCAYAAACSSPCDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "On the train set:\n",
            "Accuracy: 0.9383886255924171\n",
            "On the test set:\n",
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29kSaHDPUiAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Congrats, the test set accuracy increased to 93%. You have saved the French football team!\n",
        "\n",
        "You are not overfitting the training data anymore. Let's plot the decision boundary."
      ]
    },
    {
      "metadata": {
        "id": "GGN1S19qUiAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.title(\"Model with L2-regularization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-0.75,0.40])\n",
        "axes.set_ylim([-0.75,0.65])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Vu26yfxZUiAM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations**:\n",
        "- The value of $\\lambda$ is a hyperparameter that you can tune using a dev set.\n",
        "- L2 regularization makes your decision boundary smoother. If $\\lambda$ is too large, it is also possible to \"oversmooth\", resulting in a model with high bias.\n",
        "\n",
        "**What is L2-regularization actually doing?**:\n",
        "\n",
        "L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes. \n",
        "\n",
        "<font color='blue'>\n",
        "**What you should remember** -- the implications of L2-regularization on:\n",
        "- The cost computation:\n",
        "    - A regularization term is added to the cost\n",
        "- The backpropagation function:\n",
        "    - There are extra terms in the gradients with respect to weight matrices\n",
        "- Weights end up smaller (\"weight decay\"): \n",
        "    - Weights are pushed to smaller values."
      ]
    },
    {
      "metadata": {
        "id": "w3Q5vvXdUiAO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 - Dropout\n",
        "\n",
        "Finally, **dropout** is a widely used regularization technique that is specific to deep learning. \n",
        "**It randomly shuts down some neurons in each iteration.** Watch these two videos to see what this means!\n",
        "\n",
        "<!--\n",
        "To understand drop-out, consider this conversation with a friend:\n",
        "- Friend: \"Why do you need all these neurons to train your network and classify images?\". \n",
        "- You: \"Because each neuron contains a weight and can learn specific features/details/shape of an image. The more neurons I have, the more featurse my model learns!\"\n",
        "- Friend: \"I see, but are you sure that your neurons are learning different features and not all the same features?\"\n",
        "- You: \"Good point... Neurons in the same layer actually don't talk to each other. It should be definitly possible that they learn the same image features/shapes/forms/details... which would be redundant. There should be a solution.\"\n",
        "!--> \n",
        "\n",
        "\n",
        "<center>\n",
        "<video width=\"620\" height=\"440\" src=\"images/dropout1_kiank.mp4\" type=\"video/mp4\" controls>\n",
        "</video>\n",
        "</center>\n",
        "<br>\n",
        "<caption><center> <u> Figure 2 </u>: Drop-out on the second hidden layer. <br> At each iteration, you shut down (= set to zero) each neuron of a layer with probability $1 - keep\\_prob$ or keep it with probability $keep\\_prob$ (50% here). The dropped neurons don't contribute to the training in both the forward and backward propagations of the iteration. </center></caption>\n",
        "\n",
        "<center>\n",
        "<video width=\"620\" height=\"440\" src=\"images/dropout2_kiank.mp4\" type=\"video/mp4\" controls>\n",
        "</video>\n",
        "</center>\n",
        "\n",
        "<caption><center> <u> Figure 3 </u>: Drop-out on the first and third hidden layers. <br> $1^{st}$ layer: we shut down on average 40% of the neurons.  $3^{rd}$ layer: we shut down on average 20% of the neurons. </center></caption>\n",
        "\n",
        "\n",
        "When you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time. \n",
        "\n",
        "### 3.1 - Forward propagation with dropout\n",
        "\n",
        "**Exercise**: Implement the forward propagation with dropout. You are using a 3 layer neural network, and will add dropout to the first and second hidden layers. We will not apply dropout to the input layer or output layer. \n",
        "\n",
        "**Instructions**:\n",
        "You would like to shut down some neurons in the first and second layers. To do that, you are going to carry out 4 Steps:\n",
        "1. In lecture, we dicussed creating a variable $d^{[1]}$ with the same shape as $a^{[1]}$ using `np.random.rand()` to randomly get numbers between 0 and 1. Here, you will use a vectorized implementation, so create a random matrix $D^{[1]} = [d^{[1](1)} d^{[1](2)} ... d^{[1](m)}] $ of the same dimension as $A^{[1]}$.\n",
        "2. Set each entry of $D^{[1]}$ to be 0 with probability (`1-keep_prob`) or 1 with probability (`keep_prob`), by thresholding values in $D^{[1]}$ appropriately. Hint: to set all the entries of a matrix X to 0 (if entry is less than 0.5) or 1 (if entry is more than 0.5) you would do: `X = (X < 0.5)`. Note that 0 and 1 are respectively equivalent to False and True.\n",
        "3. Set $A^{[1]}$ to $A^{[1]} * D^{[1]}$. (You are shutting down some neurons). You can think of $D^{[1]}$ as a mask, so that when it is multiplied with another matrix, it shuts down some of the values.\n",
        "4. Divide $A^{[1]}$ by `keep_prob`. By doing this you are assuring that the result of the cost will still have the same expected value as without drop-out. (This technique is also called inverted dropout.)"
      ]
    },
    {
      "metadata": {
        "id": "NuMM-VZ8UiAP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: forward_propagation_with_dropout\n",
        "\n",
        "def forward_propagation_with_dropout(X, parameters, keep_prob = 0.5):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation: LINEAR -> RELU + DROPOUT -> LINEAR -> RELU + DROPOUT -> LINEAR -> SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset, of shape (2, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\":\n",
        "                    W1 -- weight matrix of shape (20, 2)\n",
        "                    b1 -- bias vector of shape (20, 1)\n",
        "                    W2 -- weight matrix of shape (3, 20)\n",
        "                    b2 -- bias vector of shape (3, 1)\n",
        "                    W3 -- weight matrix of shape (1, 3)\n",
        "                    b3 -- bias vector of shape (1, 1)\n",
        "    keep_prob - probability of keeping a neuron active during drop-out, scalar\n",
        "    \n",
        "    Returns:\n",
        "    A3 -- last activation value, output of the forward propagation, of shape (1,1)\n",
        "    cache -- tuple, information stored for computing the backward propagation\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    \n",
        "    # retrieve parameters\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    b3 = parameters[\"b3\"]\n",
        "    \n",
        "    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    ### START CODE HERE ### (approx. 4 lines)         # Steps 1-4 below correspond to the Steps 1-4 described above. \n",
        "    D1 = np.random.rand(A1.shape[0], A1.shape[1])     # Step 1: initialize matrix D1 = np.random.rand(..., ...)\n",
        "    D1 = D1 < keep_prob                               # Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold)\n",
        "    A1 = np.multiply(A1,D1)                           # Step 3: shut down some neurons of A1\n",
        "    A1 = A1 / keep_prob                               # Step 4: scale the value of neurons that haven't been shut down\n",
        "    ### END CODE HERE ###\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = relu(Z2)\n",
        "    ### START CODE HERE ### (approx. 4 lines)\n",
        "    D2 = np.random.rand(A2.shape[0], A2.shape[1])     # Step 1: initialize matrix D2 = np.random.rand(..., ...)\n",
        "    D2 = D2 < keep_prob                               # Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold)\n",
        "    A2 = np.multiply(A2,D2)                           # Step 3: shut down some neurons of A2\n",
        "    A2 = A2 / keep_prob                               # Step 4: scale the value of neurons that haven't been shut down\n",
        "    ### END CODE HERE ###\n",
        "    Z3 = np.dot(W3, A2) + b3\n",
        "    A3 = sigmoid(Z3)\n",
        "    \n",
        "    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)\n",
        "    \n",
        "    return A3, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXi_r6bPUiAT",
        "colab_type": "code",
        "outputId": "46cd48bc-99ab-4639-8eb9-eaae2418b098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_assess, parameters = forward_propagation_with_dropout_test_case()\n",
        "\n",
        "A3, cache = forward_propagation_with_dropout(X_assess, parameters, keep_prob = 0.7)\n",
        "print (\"A3 = \" + str(A3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A3 = [[0.36974721 0.00305176 0.04565099 0.49683389 0.36974721]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "14826Yl5UiAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**: \n",
        "\n",
        "<table> \n",
        "    <tr>\n",
        "    <td>\n",
        "    **A3**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[ 0.36974721  0.00305176  0.04565099  0.49683389  0.36974721]]\n",
        "    </td>\n",
        "    \n",
        "    </tr>\n",
        "\n",
        "</table> "
      ]
    },
    {
      "metadata": {
        "id": "iq1hG0UcUiAW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 - Backward propagation with dropout\n",
        "\n",
        "**Exercise**: Implement the backward propagation with dropout. As before, you are training a 3 layer network. Add dropout to the first and second hidden layers, using the masks $D^{[1]}$ and $D^{[2]}$ stored in the cache. \n",
        "\n",
        "**Instruction**:\n",
        "Backpropagation with dropout is actually quite easy. You will have to carry out 2 Steps:\n",
        "1. You had previously shut down some neurons during forward propagation, by applying a mask $D^{[1]}$ to `A1`. In backpropagation, you will have to shut down the same neurons, by reapplying the same mask $D^{[1]}$ to `dA1`. \n",
        "2. During forward propagation, you had divided `A1` by `keep_prob`. In backpropagation, you'll therefore have to divide `dA1` by `keep_prob` again (the calculus interpretation is that if $A^{[1]}$ is scaled by `keep_prob`, then its derivative $dA^{[1]}$ is also scaled by the same `keep_prob`).\n"
      ]
    },
    {
      "metadata": {
        "id": "1mXE5TatUiAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: backward_propagation_with_dropout\n",
        "\n",
        "def backward_propagation_with_dropout(X, Y, cache, keep_prob):\n",
        "    \"\"\"\n",
        "    Implements the backward propagation of our baseline model to which we added dropout.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset, of shape (2, number of examples)\n",
        "    Y -- \"true\" labels vector, of shape (output size, number of examples)\n",
        "    cache -- cache output from forward_propagation_with_dropout()\n",
        "    keep_prob - probability of keeping a neuron active during drop-out, scalar\n",
        "    \n",
        "    Returns:\n",
        "    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache\n",
        "    \n",
        "    dZ3 = A3 - Y\n",
        "    dW3 = 1./m * np.dot(dZ3, A2.T)\n",
        "    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)\n",
        "    dA2 = np.dot(W3.T, dZ3)\n",
        "    ### START CODE HERE ### ( 2 lines of code)\n",
        "    dA2 = np.multiply(dA2, D2)     # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation\n",
        "    dA2 = dA2 / keep_prob          # Step 2: Scale the value of neurons that haven't been shut down\n",
        "    ### END CODE HERE ###\n",
        "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
        "    dW2 = 1./m * np.dot(dZ2, A1.T)\n",
        "    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)\n",
        "    \n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    ### START CODE HERE ### ( 2 lines of code)\n",
        "    dA1 = np.multiply(dA1, D1)    # Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation\n",
        "    dA1 = dA1 / keep_prob         # Step 2: Scale the value of neurons that haven't been shut down\n",
        "    ### END CODE HERE ###\n",
        "    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n",
        "    dW1 = 1./m * np.dot(dZ1, X.T)\n",
        "    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)\n",
        "    \n",
        "    gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\"dA2\": dA2,\n",
        "                 \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2, \"dA1\": dA1, \n",
        "                 \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
        "    \n",
        "    return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFwraPzBUiAZ",
        "colab_type": "code",
        "outputId": "3daa5f47-abfb-40e6-f1cb-1669e02ab13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "X_assess, Y_assess, cache = backward_propagation_with_dropout_test_case()\n",
        "\n",
        "gradients = backward_propagation_with_dropout(X_assess, Y_assess, cache, keep_prob = 0.8)\n",
        "\n",
        "print (\"dA1 = \" + str(gradients[\"dA1\"]))\n",
        "print (\"dA2 = \" + str(gradients[\"dA2\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dA1 = [[ 0.36544439  0.         -0.00188233  0.         -0.17408748]\n",
            " [ 0.65515713  0.         -0.00337459  0.         -0.        ]]\n",
            "dA2 = [[ 0.58180856  0.         -0.00299679  0.         -0.27715731]\n",
            " [ 0.          0.53159854 -0.          0.53159854 -0.34089673]\n",
            " [ 0.          0.         -0.00292733  0.         -0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "T_VyHxXiUiAb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**: \n",
        "\n",
        "<table> \n",
        "    <tr>\n",
        "    <td>\n",
        "    **dA1**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[ 0.36544439  0.         -0.00188233  0.         -0.17408748]\n",
        " [ 0.65515713  0.         -0.00337459  0.         -0.        ]]\n",
        "    </td>\n",
        "    \n",
        "    </tr>\n",
        "    <tr>\n",
        "    <td>\n",
        "    **dA2**\n",
        "    </td>\n",
        "        <td>\n",
        "    [[ 0.58180856  0.         -0.00299679  0.         -0.27715731]\n",
        " [ 0.          0.53159854 -0.          0.53159854 -0.34089673]\n",
        " [ 0.          0.         -0.00292733  0.         -0.        ]]\n",
        "    </td>\n",
        "    \n",
        "    </tr>\n",
        "</table> "
      ]
    },
    {
      "metadata": {
        "id": "MxqGZGcyUiAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now run the model with dropout (`keep_prob = 0.86`). It means at every iteration you shut down each neurons of layer 1 and 2 with 14% probability. The function `model()` will now call:\n",
        "- `forward_propagation_with_dropout` instead of `forward_propagation`.\n",
        "- `backward_propagation_with_dropout` instead of `backward_propagation`."
      ]
    },
    {
      "metadata": {
        "id": "TO-6TflzUiAd",
        "colab_type": "code",
        "outputId": "f1540512-5ea5-43bc-9228-6907b486da69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(train_X, train_Y, keep_prob = 0.86, learning_rate = 0.3)\n",
        "\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.6543912405149825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:237: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:237: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 10000: 0.0610169865749056\n",
            "Cost after iteration 20000: 0.060582435798513114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEVCAYAAACSSPCDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "On the train set:\n",
            "Accuracy: 0.9289099526066351\n",
            "On the test set:\n",
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nhlKcW8fUiAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dropout works great! The test accuracy has increased again (to 95%)! Your model is not overfitting the training set and does a great job on the test set. The French football team will be forever grateful to you! \n",
        "\n",
        "Run the code below to plot the decision boundary."
      ]
    },
    {
      "metadata": {
        "id": "VPh5-uaVUiAh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.title(\"Model with dropout\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-0.75,0.40])\n",
        "axes.set_ylim([-0.75,0.65])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "O7ZnbJWPUiAj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "- A **common mistake** when using dropout is to use it both in training and testing. You should use dropout (randomly eliminate nodes) only in training. \n",
        "- Deep learning frameworks like [tensorflow](https://www.tensorflow.org/api_docs/python/tf/nn/dropout), [PaddlePaddle](http://doc.paddlepaddle.org/release_doc/0.9.0/doc/ui/api/trainer_config_helpers/attrs.html), [keras](https://keras.io/layers/core/#dropout) or [caffe](http://caffe.berkeleyvision.org/tutorial/layers/dropout.html) come with a dropout layer implementation. Don't stress - you will soon learn some of these frameworks.\n",
        "\n",
        "<font color='blue'>\n",
        "**What you should remember about dropout:**\n",
        "- Dropout is a regularization technique.\n",
        "- You only use dropout during training. Don't use dropout (randomly eliminate nodes) during test time.\n",
        "- Apply dropout both during forward and backward propagation.\n",
        "- During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when keep_prob is other values than 0.5.  "
      ]
    },
    {
      "metadata": {
        "id": "zkYuRGNRUiAk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4 - Conclusions"
      ]
    },
    {
      "metadata": {
        "id": "3-1dKnNzUiAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Here are the results of our three models**: \n",
        "\n",
        "<table> \n",
        "    <tr>\n",
        "        <td>\n",
        "        **model**\n",
        "        </td>\n",
        "        <td>\n",
        "        **train accuracy**\n",
        "        </td>\n",
        "        <td>\n",
        "        **test accuracy**\n",
        "        </td>\n",
        "\n",
        "    </tr>\n",
        "        <td>\n",
        "        3-layer NN without regularization\n",
        "        </td>\n",
        "        <td>\n",
        "        95%\n",
        "        </td>\n",
        "        <td>\n",
        "        91.5%\n",
        "        </td>\n",
        "    <tr>\n",
        "        <td>\n",
        "        3-layer NN with L2-regularization\n",
        "        </td>\n",
        "        <td>\n",
        "        94%\n",
        "        </td>\n",
        "        <td>\n",
        "        93%\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "        3-layer NN with dropout\n",
        "        </td>\n",
        "        <td>\n",
        "        93%\n",
        "        </td>\n",
        "        <td>\n",
        "        95%\n",
        "        </td>\n",
        "    </tr>\n",
        "</table> "
      ]
    },
    {
      "metadata": {
        "id": "k70K9wp5UiAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that regularization hurts training set performance! This is because it limits the ability of the network to overfit to the training set. But since it ultimately gives better test accuracy, it is helping your system. "
      ]
    },
    {
      "metadata": {
        "id": "6rgzxwPvUiAm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Congratulations for finishing this assignment! And also for revolutionizing French football. :-) "
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "3OzXDiYjUiAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>\n",
        "**What we want you to remember from this notebook**:\n",
        "- Regularization will help you reduce overfitting.\n",
        "- Regularization will drive your weights to lower values.\n",
        "- L2 regularization and Dropout are two very effective regularization techniques."
      ]
    },
    {
      "metadata": {
        "id": "864C4Cq0UiAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}